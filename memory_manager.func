import os
import json
import threading
import queue
from collections import deque
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
import ollama
from database import DatabaseManager

class DualMemoryManager:
    def __init__(self, short_term_capacity=10, short_term_ttl_minutes=30):
        # Database connection parameters
        self.db_params = {
            'dbname': 'funes',
            'user': 'llm',
            'password': 'llm',
            'host': 'localhost'
        }
        
        # Initialize embedding model
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Short-term memory setup
        self.short_term_memory = deque(maxlen=short_term_capacity)
        self.short_term_ttl = timedelta(minutes=short_term_ttl_minutes)
        
        # Initialize database connection
        self.db_manager = DatabaseManager(self.db_params)
        
        # Chat history for UI
        self.chat_history = []
        
        # Thread-safe queue for processing
        self.message_queue = queue.Queue()

    def retrieve_memories(self, query: str, category: str = None, top_k: int = 2) -> list:
        """
        Retrieve relevant memories from the database based on query
        
        Args:
            query: The search query
            category: Optional category filter
            top_k: Number of memories to retrieve
            
        Returns:
            list: List of relevant memory strings
        """
        print('Querying DB')
        query_embedding = self.embedding_model.encode(query)
        memories = self.db_manager.retrieve_memories(query_embedding.tolist(), top_k, category)
        return [memory[0] for memory in memories]  # Return just the text content

    def _add_to_short_term(self, role, content, category):
        """Add a message to short-term memory with timestamp and category"""
        self.short_term_memory.append({
            'role': role,
            'content': content,
            'timestamp': datetime.now(),
            'category': category
        })
    
    def _clean_short_term(self):
        """Remove expired messages from short-term memory"""
        current_time = datetime.now()
        self.short_term_memory = deque(
            [msg for msg in self.short_term_memory 
             if current_time - msg['timestamp'] <= self.short_term_ttl],
            maxlen=self.short_term_memory.maxlen
        )

    def _get_short_term_context(self):
        """Get formatted short-term memory context"""
        self._clean_short_term()
        context = "Current conversation:\n"
        for msg in self.short_term_memory:
            context += f"{msg['role']}: {msg['content']}\n"
        return context

    def process_chat(self, user_message):
        """Process chat with both short-term and long-term memory"""
        try:
            # Get current short-term context
            context = self._get_short_term_context()
            
            # Determine the category of the user message
            category = self._determine_category(user_message)
            messages = [
                {
                    'role': 'system',
                    'content': """You are Funes, a helpful assistant with access to both short-term conversation history 
                    and a long-term memory database. You can use the retrieve_memories function to search the database 
                    when you need historical context. Use your training data first, then conversation history, and 
                    finally query long-term memory if needed."""
                },
                {
                    'role': 'user',
                    'content': f"{context}\n\nCurrent user message: {user_message}"
                }
            ]
            
            # Pass the retrieve_memories function as a tool
            response = ollama.chat(
                model='llama3.2:latest'
                ,messages=messages
                ,tools=[self.retrieve_memories]
                #,stream=False
            )
            
            llm_response = response['message']['content']
            
            print('Response: '+llm_response)
            
            self._add_to_short_term('user', user_message, category)
            self._add_to_short_term('assistant', llm_response, category)
            
            # Store in long-term memory
            self.store_memory(user_message, category=category)
            self.store_memory(llm_response, category=category)
            
            # Update chat history for UI
            self.chat_history.append((user_message, llm_response))
            
            return llm_response
                
        except Exception as e:
            error_msg = f"Error processing request: {str(e)}"
            print(error_msg)
            return error_msg

    def _determine_category(self, message):
        """Determine the category/topic of the message using LLM"""
        try:
            prompt = f"""Select one category from the following list: Query to file, Information Seeking, Question Answering, 
            Topic Discussion, Opinion Sharing, Advice Request, Entertainment Conversation, Creative Writing, 
            Language Learning, Technical Support, Educational Guidance, Job Interview Simulation, Role Playing, 
            Emotional Support, Mental Health Advice, Relationship Counseling, News Discussion, Current Event Analysis, 
            Personal Storytelling, Humor Exchange, Trivia Game, Joke Telling, Game Development, Writing Feedback, 
            Language Model Design, Debugging and Maintenance and tag the following message:\n\n{message}\n\n
            Your output must be only the chosen category and nothing else."""
            
            response = ollama.chat(
                model='llama3.2:latest',
                messages=[
                    {'role': 'system', 'content': "You are a helpful assistant."},
                    {'role': 'user', 'content': prompt}
                ]
                #, stream=False
            )
            category = response['message']['content'].strip()
            return category if category else 'general'
        except Exception as e:
            print(f"Error determining category: {str(e)}")
            return 'general'
    
    def store_memory(self, context, category='general', source='chat'):
        """Store memory in long-term storage (PostgreSQL)"""
        embedding = self.embedding_model.encode(context)
        self.db_manager.insert_memory(context, embedding, category, source)
    
    def clear_memories(self):
        """Clear all memories"""
        self.short_term_memory.clear()
        self.db_manager.clear_memories()
        return "All memories cleared successfully."
